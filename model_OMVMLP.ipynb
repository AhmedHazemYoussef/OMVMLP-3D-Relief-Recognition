{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,Subset, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get number of classes from label_mapping.json\n",
    "def get_num_classes(label_mapping_path):\n",
    "    with open(label_mapping_path, 'r') as f:\n",
    "        label_mapping = json.load(f)\n",
    "    return len(set(label_mapping.values()))\n",
    "\n",
    "# Function to extract file_index and labels from folder name\n",
    "def parse_folder_name(folder_name):\n",
    "    parts = folder_name.split('_pattern_')\n",
    "    if len(parts) != 2:\n",
    "        return None, None\n",
    "    file_index = parts[0]\n",
    "    pattern_indices = parts[1].split('_')\n",
    "    return file_index, [int(idx) for idx in pattern_indices]\n",
    "\n",
    "# Function to create one-hot encoded labels\n",
    "def create_one_hot_labels(pattern_indices, num_classes):\n",
    "    one_hot = np.zeros(num_classes, dtype=np.float32)\n",
    "    for idx in pattern_indices:\n",
    "        one_hot[idx - 1] = 1  # 1-based to 0-based\n",
    "    return one_hot\n",
    "\n",
    "# Function to get unique labels\n",
    "def get_unique_labels(data_dir):\n",
    "    unique_labels = set()\n",
    "    for folder_name in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        parts = folder_name.split('_pattern_')\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        labels = [int(label) for label in parts[1].split('_')]\n",
    "        unique_labels.update(labels)\n",
    "    return unique_labels\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(loader, model, device):\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    with torch.no_grad():\n",
    "        for images, _, folder_names in loader:  # Ignore the placeholder\n",
    "            images = images.to(device)\n",
    "            features = model(images, return_features=True)  # (batch_size, 512)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "    return np.concatenate(features_list, axis=0)  # (num_samples, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class MultiViewDataset(Dataset):\n",
    "    def __init__(self, data_dirs, view_names, num_classes, img_size=(512, 512), transform=None, is_query=False, is_retrieval=False, white_views=None):\n",
    "        self.data_dirs = data_dirs\n",
    "        self.view_names = view_names\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.is_query = is_query\n",
    "        self.is_retrieval = is_retrieval\n",
    "        self.white_views = white_views if white_views is not None else {}\n",
    "        self.samples = []\n",
    "\n",
    "        for data_dir in data_dirs:\n",
    "            for folder_name in os.listdir(data_dir):\n",
    "                folder_path = os.path.join(data_dir, folder_name)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    continue\n",
    "                file_index, pattern_indices = parse_folder_name(folder_name)\n",
    "                all_views_exist = all(os.path.exists(os.path.join(folder_path, f\"{view}.png\")) for view in view_names)\n",
    "                if not all_views_exist:\n",
    "                    continue\n",
    "                if self.is_retrieval or pattern_indices is None:\n",
    "                    self.samples.append(folder_path)  # Just the path for retrieval\n",
    "                else:\n",
    "                    self.samples.append((folder_path, pattern_indices))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_retrieval:\n",
    "            folder_path = self.samples[idx]\n",
    "            pattern_indices = None\n",
    "        else:\n",
    "            sample = self.samples[idx]\n",
    "            if isinstance(sample, str):\n",
    "                folder_path = sample\n",
    "                pattern_indices = None\n",
    "            else:\n",
    "                folder_path, pattern_indices = sample\n",
    "        \n",
    "        folder_name = os.path.basename(folder_path)\n",
    "        images = []\n",
    "        for view in self.view_names:\n",
    "            img_path = os.path.join(folder_path, f\"{view}.png\")\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            images.append(img)\n",
    "        images = torch.stack(images)  # (num_views, 3, H, W)\n",
    "\n",
    "        if self.is_retrieval:\n",
    "            return images, torch.tensor([]), folder_name  \n",
    "        elif self.is_query:\n",
    "            label = create_one_hot_labels(pattern_indices, 19) if pattern_indices else np.zeros(19)\n",
    "            return images, torch.tensor(label, dtype=torch.float32), folder_name\n",
    "        else:\n",
    "            label = create_one_hot_labels(pattern_indices, self.num_classes) if pattern_indices else np.zeros(self.num_classes)\n",
    "            return images, torch.tensor(label, dtype=torch.float32), folder_name\n",
    "        \n",
    "# Wrapper dataset to filter labels to only the last 4 classes (indices 15-18)\n",
    "class FilteredLabelDataset(Dataset):\n",
    "    def __init__(self, dataset, original_num_classes, target_num_classes, start_class_idx):\n",
    "        self.dataset = dataset\n",
    "        self.original_num_classes = original_num_classes  # 19 classes\n",
    "        self.target_num_classes = target_num_classes  # 4 classes\n",
    "        self.start_class_idx = start_class_idx  # Start index for filtering (15)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, label, folder_name = self.dataset[idx]\n",
    "        # Extract the last 4 classes (indices 15-18) from the 19-class one-hot vector\n",
    "        filtered_label = label[self.start_class_idx:self.start_class_idx + self.target_num_classes]\n",
    "        return images, filtered_label, folder_name        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"E:/Ahmed/IMT Nord Europe/3D/Training_Screenshots/train\"\n",
    "val_dir = \"E:/Ahmed/IMT Nord Europe/3D/Training_Screenshots/val\"\n",
    "query_dir = \"E:/Ahmed/IMT Nord Europe/3D/Query_Screenshots\"\n",
    "retrieval_dir = \"E:/Ahmed/IMT Nord Europe/3D/Retrieval_Screenshots\"\n",
    "label_mapping_path = \"label_mapping_2.json\"\n",
    "\n",
    "# Get the number of classes\n",
    "num_training_query_classes = get_num_classes(label_mapping_path)\n",
    "train_labels = get_unique_labels(train_dir)\n",
    "num_classes = len(train_labels)\n",
    "print(f\"Number of classes (original training): {num_classes}\")\n",
    "\n",
    "# Number of classes in query dataset\n",
    "num_classes_query = 19  # Updated to 19 classes\n",
    "num_classes_finetune = 4  # Last 4 classes for fine-tuning (indices 15-18)\n",
    "\n",
    "# Define view names\n",
    "view_names = [\"top\", \"bottom\", \"lateral_1\", \"lateral_2\", \"lateral_3\", \"lateral_4\"]\n",
    "\n",
    "# Image size\n",
    "img_size = (512, 512)\n",
    "\n",
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Preprocessing datasets\n",
    "print(\"Preprocessing training data...\")\n",
    "train_dataset = MultiViewDataset([train_dir], view_names, num_classes, img_size, transform)\n",
    "\n",
    "print(\"Preprocessing validation data...\")\n",
    "val_dataset = MultiViewDataset([val_dir], view_names, num_classes, img_size, transform)\n",
    "\n",
    "print(\"Preprocessing query data...\")\n",
    "query_dataset = MultiViewDataset([query_dir], view_names, num_classes_query, img_size, transform, is_query=True)\n",
    "\n",
    "print(\"Preprocessing retrieval data...\")\n",
    "retrieval_dataset = MultiViewDataset([retrieval_dir], view_names, num_classes, img_size, transform, is_retrieval=True)\n",
    "\n",
    "# Extract labels from query dataset and identify relevant samples\n",
    "query_labels = []\n",
    "relevant_indices = []  # Indices of samples with at least one of the last 4 classes active\n",
    "for idx in range(len(query_dataset)):\n",
    "    _, label, _ = query_dataset[idx]  # label is torch.tensor of dtype torch.float32 (one-hot encoded)\n",
    "    active_classes = label.nonzero(as_tuple=True)[0].numpy()  # Indices where label is 1\n",
    "    query_labels.append(active_classes)\n",
    "\n",
    "    # Check if the sample has at least one of the last 4 classes (indices 15-18) active\n",
    "    last_four = label[-4:].numpy()  # Last 4 indices (15-18)\n",
    "    if last_four.sum() > 0:  # At least one of the last 4 classes is active\n",
    "        relevant_indices.append(idx)\n",
    "\n",
    "print(f\"Total query samples: {len(query_dataset)}\")\n",
    "print(f\"Relevant query samples (with at least one of classes 15-18 active): {len(relevant_indices)}\")\n",
    "\n",
    "# Perform stratified split on relevant samples\n",
    "def stratified_split_relevant_samples(dataset, labels, relevant_indices, test_size=0.2, random_state=42):\n",
    "    if not relevant_indices:\n",
    "        print(\"No relevant samples found with classes 15-18 active. Cannot perform split.\")\n",
    "        return [], []\n",
    "\n",
    "    # Extract labels for relevant samples\n",
    "    relevant_labels = [labels[idx] for idx in relevant_indices]\n",
    "\n",
    "    # For stratification, use the active classes within the last 4 (15-18) as the primary label\n",
    "    primary_labels = []\n",
    "    for label in relevant_labels:\n",
    "        # Get active classes in the range 15-18\n",
    "        active_last_four = [cls for cls in label if cls >= 15 and cls <= 18]\n",
    "        if active_last_four:\n",
    "            primary_labels.append(active_last_four[0])  # Use the first active class in 15-18\n",
    "        else:\n",
    "            primary_labels.append(-1)  # Shouldn't happen due to relevant_indices filtering\n",
    "\n",
    "    # Perform stratified split on relevant indices\n",
    "    train_indices_rel, val_indices_rel = train_test_split(\n",
    "        relevant_indices,\n",
    "        test_size=test_size,\n",
    "        stratify=primary_labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    return train_indices_rel, val_indices_rel\n",
    "\n",
    "# Perform the stratified split on relevant samples\n",
    "train_indices, val_indices = stratified_split_relevant_samples(\n",
    "    query_dataset, query_labels, relevant_indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Create subsets for fine-tuning\n",
    "query_train_dataset = Subset(query_dataset, train_indices)\n",
    "query_val_dataset = Subset(query_dataset, val_indices)\n",
    "\n",
    "# Create filtered datasets for fine-tuning\n",
    "query_train_dataset_filtered = FilteredLabelDataset(\n",
    "    query_train_dataset,\n",
    "    original_num_classes=num_classes_query,\n",
    "    target_num_classes=num_classes_finetune,\n",
    "    start_class_idx=15  # Start at index 15 (for classes 15-18)\n",
    ")\n",
    "\n",
    "query_val_dataset_filtered = FilteredLabelDataset(\n",
    "    query_val_dataset,\n",
    "    original_num_classes=num_classes_query,\n",
    "    target_num_classes=num_classes_finetune,\n",
    "    start_class_idx=15\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "query_loader = DataLoader(query_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "retrieval_loader = DataLoader(retrieval_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# New data loaders for fine-tuning with filtered labels\n",
    "query_train_loader = DataLoader(query_train_dataset_filtered, batch_size=16, shuffle=True, num_workers=0)\n",
    "query_val_loader = DataLoader(query_val_dataset_filtered, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# Verify class distribution in training and validation sets\n",
    "def print_class_distribution(dataset, name, num_classes=19):\n",
    "    class_counts = np.zeros(num_classes)\n",
    "    for idx in range(len(dataset)):\n",
    "        _, label, _ = dataset[idx]  # label is torch.tensor of dtype torch.float32\n",
    "        active_classes = label.nonzero(as_tuple=True)[0].numpy()\n",
    "        for cls in active_classes:\n",
    "            class_counts[cls] += 1\n",
    "    print(f\"\\nClass distribution in {name}:\")\n",
    "    for cls, count in enumerate(class_counts):\n",
    "        print(f\"Class {cls}: {int(count)} samples\")\n",
    "\n",
    "print_class_distribution(query_dataset, \"Query Dataset\", num_classes_query)\n",
    "print_class_distribution(query_train_dataset, \"Query Training Dataset (fine-tuning)\", num_classes_query)\n",
    "print_class_distribution(query_val_dataset, \"Query Validation Dataset (fine-tuning)\", num_classes_query)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"\\nTraining samples (original): {len(train_dataset)}\")\n",
    "print(f\"Validation samples (original): {len(val_dataset)}\")\n",
    "print(f\"Query samples: {len(query_dataset)}\")\n",
    "print(f\"Query training samples (for fine-tuning): {len(query_train_dataset)}\")\n",
    "print(f\"Query validation samples (for fine-tuning): {len(query_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "# Load pretrained VGG19\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "\n",
    "# Unfreeze the last few layers of VGG19 for fine-tuning\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in vgg19.features[-3:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Remove the default classifier\n",
    "vgg19.classifier = nn.Identity()\n",
    "\n",
    "class MultiView(nn.Module):\n",
    "    def __init__(self, num_views, num_classes, model, svms=None, scaler=None, device=None):\n",
    "        super(MultiView, self).__init__()\n",
    "        self.num_views = num_views\n",
    "        self.model = model\n",
    "        self.svms = svms\n",
    "        self.scaler = scaler\n",
    "        self.feature_dim = self.model.features(torch.randn(1, 3, 512, 512)).shape[1]\n",
    "        self.device = device\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_views * self.feature_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, views, return_features=False, svm=False):\n",
    "        batch_size = views.size(0)\n",
    "        view_features = []\n",
    "        for i in range(self.num_views):\n",
    "            view = views[:, i]\n",
    "            feat = self.model.features(view)\n",
    "            feat = nn.AdaptiveAvgPool2d(1)(feat)\n",
    "            feat = feat.view(batch_size, -1)\n",
    "            view_features.append(feat)\n",
    "        concatenated_features = torch.cat(view_features, dim=1)\n",
    "        if return_features:\n",
    "            features_512 = self.classifier[0](concatenated_features)\n",
    "            features_512 = self.classifier[1](features_512)\n",
    "            return features_512\n",
    "        if svm:\n",
    "            # SVM path (not used in summary)\n",
    "            pass\n",
    "        output = self.classifier(concatenated_features)\n",
    "        return output\n",
    "\n",
    "# Instantiate the model\n",
    "num_views = 6  # Example: 6 views\n",
    "num_classes = 10  # Example: 10 classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiView(num_views=num_views, num_classes=num_classes, model=vgg19).to(device)\n",
    "\n",
    "# Print model summary\n",
    "# Input shape: (channels, height, width) per view, but we need to account for num_views\n",
    "# torchsummary expects input shape as (channels, height, width), so we simulate one view\n",
    "print(\"Model Summary for one view (repeated internally for num_views):\")\n",
    "summary(model.model.features, input_size=(3, 512, 512))  # Summarize VGG19 features\n",
    "print(\"\\nCustom Classifier Summary:\")\n",
    "summary(model.classifier, input_size=(num_views * 512,))  # Summarize classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated Training and Evaluation Function\n",
    "def train_and_evaluate_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15, device='cuda', threshold=0.5, model_path_loss=\"best_model_loss.pth\", model_path_f1=\"best_model_f1.pth\"):\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_f1 = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_f1_scores, val_f1_scores = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        train_outputs = []\n",
    "\n",
    "        for batch_idx, (images, labels, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Train\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Logits or probabilities depending on model\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Collect outputs and labels\n",
    "            batch_outputs = outputs.detach().cpu().numpy()\n",
    "            batch_labels = labels.detach().cpu().numpy()\n",
    "            train_outputs.append(batch_outputs)\n",
    "            train_labels.append(batch_labels)\n",
    "\n",
    "            # Fixed threshold predictions\n",
    "            preds = (outputs > threshold).float()\n",
    "            train_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "        # Compute Training Metrics\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_outputs = np.concatenate(train_outputs)\n",
    "        train_labels = np.concatenate(train_labels)\n",
    "        train_preds = np.concatenate(train_preds)\n",
    "\n",
    "        train_f1 = f1_score(train_labels, train_preds, average='micro', zero_division=0)\n",
    "        train_accuracy = np.mean(np.all(train_preds == train_labels, axis=1))  # Strict accuracy\n",
    "\n",
    "        # Store training metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_f1_scores.append(train_f1)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_outputs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, labels, _) in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Val\")):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)  \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                batch_outputs = outputs.detach().cpu().numpy()\n",
    "                batch_labels = labels.detach().cpu().numpy()\n",
    "                val_outputs.append(batch_outputs)\n",
    "                val_labels.append(batch_labels)\n",
    "\n",
    "                # Fixed threshold predictions\n",
    "                preds = (outputs > threshold).float()\n",
    "                val_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "                # Print first few batches\n",
    "                if batch_idx < 3:\n",
    "                    print(f\"\\nVal Batch {batch_idx + 1}\")\n",
    "                    print(\"Raw Outputs (first sample):\", batch_outputs[0])\n",
    "                    print(\"Predicted Labels (first sample):\", preds[0].cpu().numpy())\n",
    "                    print(\"True Labels (first sample):\", batch_labels[0])\n",
    "\n",
    "        # Compute Validation Metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_outputs = np.concatenate(val_outputs)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "\n",
    "        val_output_mean, val_output_std = np.mean(val_outputs), np.std(val_outputs)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "        val_precision = precision_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "        val_recall = recall_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "        val_accuracy = np.mean(np.all(val_preds == val_labels, axis=1))  # Strict accuracy\n",
    "\n",
    "        # Store validation metrics\n",
    "        val_losses.append(val_loss)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print Epoch Results\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Val - Loss: {val_loss:.4f}, F1: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Val Output Distribution - Mean: {val_output_mean:.4f}, Std: {val_output_std:.4f}\")\n",
    "\n",
    "        # Save Best Model Based on Validation Loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path_loss)\n",
    "            print(f\"Best model (loss) saved with Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        # Save Best Model Based on Validation F1 Score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_path_f1)\n",
    "            print(f\"Best model (F1) saved with Val F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Return all metrics for potential analysis\n",
    "    return {\n",
    "        'train_losses': train_losses, 'val_losses': val_losses,\n",
    "        'train_f1_scores': train_f1_scores, 'val_f1_scores': val_f1_scores,\n",
    "        'train_accuracies': train_accuracies, 'val_accuracies': val_accuracies\n",
    "    }\n",
    "\n",
    "# Setup and Run\n",
    "view_names = [\"top\", \"bottom\", \"lateral_1\", \"lateral_2\", \"lateral_3\", \"lateral_4\"]\n",
    "num_views = len(view_names)  \n",
    "num_classes = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_vgg19_15 = MultiView(\n",
    "    num_views=num_views,\n",
    "    num_classes=num_classes,\n",
    "    model=vgg19  \n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_vgg19_15.parameters()), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-5)\n",
    "\n",
    "# Train and Evaluate\n",
    "metrics = train_and_evaluate_model(\n",
    "    model=model_vgg19_15,\n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader,      \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,\n",
    "    device=device,\n",
    "    threshold=0.5,\n",
    "    model_path_loss=\"best_model_loss.pth\",\n",
    "    model_path_f1=\"best_model_f1.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training 4-class model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Integrated Training and Evaluation Function\n",
    "def fine_tune_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15, device='cuda', threshold=0.5, model_path_loss=\"best_model_loss.pth\", model_path_f1=\"best_model_f1.pth\"):\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_f1 = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_f1_scores, val_f1_scores = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        train_outputs = []\n",
    "\n",
    "        for batch_idx, (images, labels, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Train\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Logits or probabilities depending on model\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Collect outputs and labels\n",
    "            batch_outputs = outputs.detach().cpu().numpy()\n",
    "            batch_labels = labels.detach().cpu().numpy()\n",
    "            train_outputs.append(batch_outputs)\n",
    "            train_labels.append(batch_labels)\n",
    "\n",
    "            # Fixed threshold predictions\n",
    "            preds = (outputs > threshold).float()\n",
    "            train_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "        # Compute Training Metrics\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_outputs = np.concatenate(train_outputs)\n",
    "        train_labels = np.concatenate(train_labels)\n",
    "        train_preds = np.concatenate(train_preds)\n",
    "\n",
    "        train_f1 = f1_score(train_labels, train_preds, average='micro', zero_division=0)\n",
    "        train_accuracy = np.mean(np.all(train_preds == train_labels, axis=1))  # Strict accuracy\n",
    "\n",
    "        # Store training metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_f1_scores.append(train_f1)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_outputs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, labels, _) in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Val\")):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)  \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                batch_outputs = outputs.detach().cpu().numpy()\n",
    "                batch_labels = labels.detach().cpu().numpy()\n",
    "                val_outputs.append(batch_outputs)\n",
    "                val_labels.append(batch_labels)\n",
    "\n",
    "                # Fixed threshold predictions\n",
    "                preds = (outputs > threshold).float()\n",
    "                val_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "                # Print first few batches\n",
    "                if batch_idx < 3:\n",
    "                    print(f\"\\nVal Batch {batch_idx + 1}\")\n",
    "                    print(\"Raw Outputs (first sample):\", batch_outputs[0])\n",
    "                    print(\"Predicted Labels (first sample):\", preds[0].cpu().numpy())\n",
    "                    print(\"True Labels (first sample):\", batch_labels[0])\n",
    "\n",
    "        # Compute Validation Metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_outputs = np.concatenate(val_outputs)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "\n",
    "        val_output_mean, val_output_std = np.mean(val_outputs), np.std(val_outputs)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "        val_precision = precision_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "        val_recall = recall_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "        val_accuracy = np.mean(np.all(val_preds == val_labels, axis=1))  # Strict accuracy\n",
    "\n",
    "        # Store validation metrics\n",
    "        val_losses.append(val_loss)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print Epoch Results\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Val - Loss: {val_loss:.4f}, F1: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Val Output Distribution - Mean: {val_output_mean:.4f}, Std: {val_output_std:.4f}\")\n",
    "\n",
    "        # Save Best Model Based on Validation Loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path_loss)\n",
    "            print(f\"Best model (loss) saved with Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        # Save Best Model Based on Validation F1 Score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_path_f1)\n",
    "            print(f\"Best model (F1) saved with Val F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Return all metrics for potential analysis\n",
    "    return {\n",
    "        'train_losses': train_losses, 'val_losses': val_losses,\n",
    "        'train_f1_scores': train_f1_scores, 'val_f1_scores': val_f1_scores,\n",
    "        'train_accuracies': train_accuracies, 'val_accuracies': val_accuracies\n",
    "    }\n",
    "\n",
    "# Setup and Run\n",
    "view_names = [\"top\", \"bottom\", \"lateral_1\", \"lateral_2\", \"lateral_3\", \"lateral_4\"]\n",
    "num_views = len(view_names)  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_fine_tuned = MultiView(\n",
    "    num_views=num_views,\n",
    "    num_classes=4,\n",
    "    model=vgg19,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Load pretrained weights\n",
    "state_dict = torch.load(\"best_model_f1_VGG.pth\")\n",
    "\n",
    "# Keep only the weights for classifier[0] (first layer producing 512 channels)\n",
    "# Remove weights for other classifier layers\n",
    "keys_to_remove = [key for key in state_dict.keys() if key.startswith('classifier') and key not in ['classifier.0.weight', 'classifier.0.bias']]\n",
    "for key in keys_to_remove:\n",
    "    state_dict.pop(key)\n",
    "\n",
    "# Load the modified state dictionary into the model\n",
    "# Use strict=False since we're intentionally missing some classifier weights\n",
    "model_fine_tuned.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Freeze the backbone (VGG19 features)\n",
    "for param in model_fine_tuned.model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Reinitialize the classifier, preserving classifier[0] weights\n",
    "num_classes_finetune = 4\n",
    "in_features = model_fine_tuned.num_views * model_fine_tuned.feature_dim  # Should be 6 * 512 = 3072\n",
    "\n",
    "# Save the pre-trained weights of classifier[0]\n",
    "classifier_0_weight = model_fine_tuned.classifier[0].weight.clone()\n",
    "classifier_0_bias = model_fine_tuned.classifier[0].bias.clone()\n",
    "\n",
    "# Create a new classifier with the same architecture\n",
    "model_fine_tuned.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),  # classifier[0]: 3072 -> 512\n",
    "    nn.ReLU(),                    # classifier[1]\n",
    "    nn.Dropout(0.5),              # classifier[2]\n",
    "    nn.Linear(512, 128),          # classifier[3]: 512 -> 128\n",
    "    nn.ReLU(),                    # classifier[4]\n",
    "    nn.Dropout(0.5),              # classifier[5]\n",
    "    nn.Linear(128, num_classes_finetune),  # classifier[6]: 128 -> 4\n",
    "    nn.Sigmoid()                  # classifier[7]\n",
    ").to(device)\n",
    "\n",
    "# Restore the pre-trained weights for classifier[0]\n",
    "model_fine_tuned.classifier[0].weight.data = classifier_0_weight\n",
    "model_fine_tuned.classifier[0].bias.data = classifier_0_bias\n",
    "\n",
    "# Initialize the remaining linear layers with random weights\n",
    "# classifier[3] (Linear: 512 -> 128)\n",
    "nn.init.kaiming_normal_(model_fine_tuned.classifier[3].weight, mode='fan_out', nonlinearity='relu')\n",
    "nn.init.zeros_(model_fine_tuned.classifier[3].bias)\n",
    "\n",
    "# classifier[6] (Linear: 128 -> 4)\n",
    "nn.init.kaiming_normal_(model_fine_tuned.classifier[6].weight, mode='fan_out', nonlinearity='relu')\n",
    "nn.init.zeros_(model_fine_tuned.classifier[6].bias)\n",
    "\n",
    "# Ensure the entire classifier is trainable\n",
    "for param in model_fine_tuned.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify which parameters are trainable\n",
    "print(\"Trainable parameters after setup:\")\n",
    "for name, param in model_fine_tuned.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "\n",
    "# Optimizer and training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_fine_tuned.parameters()), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-4)\n",
    "\n",
    "metrics = fine_tune_model(\n",
    "    model=model_fine_tuned,\n",
    "    train_loader=query_train_loader,\n",
    "    val_loader=query_val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,\n",
    "    device=device,\n",
    "    threshold=0.5,\n",
    "    model_path_loss=\"finetuned_model_loss_VGG_4_class_classifier_unfrozen_first_layer_loaded.pth\",\n",
    "    model_path_f1=\"finetuned_model_f1_VGG_4_class_classifier_unfrozen_first_layer_loaded.pth\"\n",
    ")\n",
    "\n",
    "# Optionally, load the best fine-tuned models\n",
    "print(\"\\nLoading best fine-tuned model based on validation loss...\")\n",
    "model_fine_tuned.load_state_dict(torch.load(\"finetuned_model_loss_VGG_4_class_classifier_unfrozen.pth\"))\n",
    "model_fine_tuned.eval()\n",
    "\n",
    "print(\"\\nLoading best fine-tuned model based on F1 score...\")\n",
    "model_fine_tuned.load_state_dict(torch.load(\"finetuned_model_f1_VGG_4_class_classifier_unfrozen.pth\"))\n",
    "model_fine_tuned.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = len(view_names)  \n",
    "num_classes = 4  \n",
    "num_classes_finetune = 4\n",
    "\n",
    "# Initialize the model with the new naming convention (self.model)\n",
    "# model = MultiView(\n",
    "#     num_views=num_views,\n",
    "#     num_classes=num_classes,\n",
    "#     model=vgg19\n",
    "# ).to(device)\n",
    "\n",
    "# # Load the checkpoint and modify the state dictionary keys\n",
    "# checkpoint_path = \"finetuned_model_f1_VGG_4_class.pth\"\n",
    "# state_dict = torch.load(checkpoint_path)\n",
    "\n",
    "# # Create a new state dictionary with updated keys\n",
    "# new_state_dict = {}\n",
    "# # for key, value in state_dict.items():\n",
    "# #     # Replace 'mobilenet' with 'model' in the key names\n",
    "# #     new_key = key.replace('mobilenet', 'model')\n",
    "# #     new_state_dict[new_key] = value\n",
    "\n",
    "# # Load the modified state dictionary into the model\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "#model.eval()\n",
    "\n",
    "model_4class = MultiView(\n",
    "    num_views=num_views,\n",
    "    num_classes=num_classes_finetune,\n",
    "    model=vgg19\n",
    ").to(device)\n",
    "\n",
    "model_4class.load_state_dict(torch.load(\"finetuned_model_f1_VGG_4_class_classifier_unfrozen.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, _) in enumerate(tqdm(val_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  \n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            batch_outputs = outputs.detach().cpu().numpy()\n",
    "            batch_labels = labels.detach().cpu().numpy()\n",
    "            val_outputs.append(batch_outputs)\n",
    "            val_labels.append(batch_labels)\n",
    "            # Fixed threshold predictions\n",
    "            preds = (outputs > 0.5).float()\n",
    "            val_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    # Compute validation metrics\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_outputs = np.concatenate(val_outputs)\n",
    "    val_labels = np.concatenate(val_labels)\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "\n",
    "    # Analyze validation output distribution\n",
    "    val_output_mean, val_output_std = np.mean(val_outputs), np.std(val_outputs)\n",
    "    print(f\"Validation Output Distribution - Mean: {val_output_mean:.4f}, Std: {val_output_std:.4f}\")\n",
    "\n",
    "    # Compute per-class metrics using classification_report\n",
    "    class_names = [str(i) for i in range(val_labels.shape[1])]  # Class names as 0 to 14\n",
    "    report = classification_report(\n",
    "        val_labels,\n",
    "        val_preds,\n",
    "        target_names=class_names,\n",
    "        zero_division=0,\n",
    "        output_dict=False  # Set to True if you want a dictionary instead\n",
    "    )\n",
    "    print(\"\\nPer-class Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Compute overall metrics for adaptive thresholds\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "    val_precision = precision_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "    val_recall = recall_score(val_labels, val_preds, average='micro', zero_division=0)\n",
    "    val_accuracy = np.mean(np.all(val_preds == val_labels, axis=1))\n",
    "\n",
    "    # Print overall metrics\n",
    "    print(\"\\nEvaluation Results (Classifier)\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}, Val Precision: {val_precision:.4f}, \"\n",
    "          f\"Val Recall: {val_recall:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return val_loss, val_f1, val_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, load the best models after training (choose one or both based on your needs)\n",
    "# print(\"\\nLoading best model based on validation loss...\")\n",
    "# model_vgg19_15.load_state_dict(torch.load(\"best_model_loss.pth\"))\n",
    "# model_vgg19_15.eval()\n",
    "\n",
    "# print(\"\\nLoading best model based on F1 score...\")\n",
    "# model_vgg19_15.load_state_dict(torch.load(\"best_model_f1_VGG.pth\"))\n",
    "# model_vgg19_15.eval()\n",
    "\n",
    "# Evaluate the classifier\n",
    "val_loss_classifier, val_f1_classifier, val_accuracy_classifier = evaluate_model(\n",
    "    model=model_4class,\n",
    "    val_loader=query_val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for training and validation sets\n",
    "train_features, train_labels = extract_features(train_loader, model_classifier, num_views, device)\n",
    "val_features, val_labels = extract_features(val_loader, model_classifier, num_views, device)\n",
    "\n",
    "# Standardize the features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "val_features = scaler.transform(val_features)\n",
    "\n",
    "# Train an SVM with RBF kernel for each class (one-vs-rest for multi-label)\n",
    "svms = []\n",
    "for class_idx in range(num_classes):\n",
    "    print(f\"Training SVM for class {class_idx + 1}/{num_classes}...\")\n",
    "    svm = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
    "    svm.fit(train_features, train_labels[:, class_idx])\n",
    "    svms.append(svm)\n",
    "\n",
    "# Instantiate a new MultiViewModel for SVM-based classification\n",
    "model_svm = MultiView(\n",
    "    num_views=num_views,\n",
    "    num_classes=num_classes,\n",
    "    model=mobilenet_v3,\n",
    "    svms=svms,\n",
    "    scaler=scaler,\n",
    "    device=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_svm, val_f1_svm, val_accuracy_svm = evaluate_model(\n",
    "    model=model_svm,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    svm = True,\n",
    "    k=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# CNN Feature Extractor (unchanged)\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc = nn.Linear(256 * 32 * 32, 512)  # For 512x512 input\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Multi-View CNN Classifier (unchanged)\n",
    "class MultiViewCNN(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(MultiViewCNN, self).__init__()\n",
    "        self.feature_extractor = CNNFeatureExtractor()\n",
    "        self.final_fc = nn.Sequential(\n",
    "            nn.Linear(512 * 6, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_views, channels, height, width = x.shape\n",
    "        x = x.view(batch_size * num_views, channels, height, width)\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(batch_size, num_views, -1)\n",
    "        features = features.view(batch_size, -1)\n",
    "        out = self.final_fc(features)\n",
    "        return out\n",
    "\n",
    "# Updated Training Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, model_path=\"best_model.pth\", threshold=0.5):\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for images, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Train\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "        all_val_probs = []\n",
    "        batch_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Val\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)  # Logits\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Convert logits to probabilities\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                # Threshold predictions\n",
    "                preds = (probs > threshold).float()\n",
    "\n",
    "                # Store for metrics\n",
    "                all_val_labels.append(labels.cpu().numpy())\n",
    "                all_val_preds.append(preds.cpu().numpy())\n",
    "                all_val_probs.append(probs.cpu().numpy())\n",
    "\n",
    "                # Visualize first three batches\n",
    "                if batch_count < 3:\n",
    "                    print(f\"\\nValidation Batch {batch_count + 1}:\")\n",
    "                    print(\"True Labels:\", labels.cpu().numpy()[:2])  # Show first 2 samples\n",
    "                    print(\"Raw Probabilities:\", probs.cpu().numpy()[:2])\n",
    "                    print(\"Thresholded Predictions (>{threshold}):\", preds.cpu().numpy()[:2])\n",
    "                batch_count += 1\n",
    "\n",
    "        # Compute Metrics\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_val_labels = np.concatenate(all_val_labels, axis=0)  # (num_samples, num_classes)\n",
    "        all_val_preds = np.concatenate(all_val_preds, axis=0)    # (num_samples, num_classes)\n",
    "        all_val_probs = np.concatenate(all_val_probs, axis=0)    # (num_samples, num_classes)\n",
    "\n",
    "        # Validation Accuracy (strict: all labels must match)\n",
    "        correct_samples = np.all(all_val_preds == all_val_labels, axis=1)  # True if all labels match\n",
    "        val_accuracy = np.mean(correct_samples) * 100  # Percentage\n",
    "\n",
    "        # F1 Score (micro: element-wise across all labels)\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='micro', zero_division=0)\n",
    "\n",
    "        # Print Results\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Val Accuracy (strict): {val_accuracy:.2f}%, Val F1 (micro): {val_f1:.4f}\")\n",
    "\n",
    "        # Save Best Model (based on loss, not accuracy)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "# Load Model Function (unchanged)\n",
    "def load_best_model(model, model_path=\"best_model.pth\"):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 15\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "threshold = 0.5  # For thresholding predictions\n",
    "\n",
    "# Model Setup\n",
    "model = MultiViewCNN(num_classes).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Train and Save Best Model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, model_path=\"best_model.pth\", threshold=threshold)\n",
    "\n",
    "# Load the Best Model\n",
    "model = load_best_model(model, \"best_model.pth\")\n",
    "\n",
    "# Inference Example\n",
    "test_images = torch.randn(1, 6, 3, 512, 512).to(device)  # Fixed channels from 1 to 3\n",
    "with torch.no_grad():\n",
    "    logits = model(test_images)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    print(\"Predicted class probabilities:\", probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation in membership matrix (main approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec 1\n",
    "generating the text files of the features, and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# Paths\n",
    "query_csv_path = \"query_labels_new_2.csv\"\n",
    "obj_dir = \"E:/Ahmed/IMT Nord Europe/3D/Retrieval_Screenshots_2\"\n",
    "num_classes = 15  # Number of trained classes\n",
    "num_classes_finetune = 4  # Number of fine-tuned classes (15-18, re-indexed as 0-3)\n",
    "\n",
    "# Step 1: Get number of validation objects (M) and sort them ascendingly\n",
    "objects = [f for f in os.listdir(obj_dir) if os.path.isdir(os.path.join(obj_dir, f))]\n",
    "objects = sorted(objects, key=lambda x: int(x))  # Sort by integer value\n",
    "M = len(objects)\n",
    "object_indices = {obj: i for i, obj in enumerate(objects)}\n",
    "print(f\"Number of objects (M): {M}\")\n",
    "print(f\"Sorted objects: {objects[:10]}...\")\n",
    "\n",
    "# Step 2: Read query CSV and preserve exact pattern sequence\n",
    "query_df = pd.read_csv(query_csv_path)\n",
    "query_patterns = []  # List of (file_index, pattern) tuples\n",
    "\n",
    "for _, row in query_df.iterrows():\n",
    "    file_index = str(int(row['file_index']))\n",
    "    if pd.notna(row['pattern_1']):\n",
    "        pattern = int(row['pattern_1'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "    if pd.notna(row['pattern_2']):\n",
    "        pattern = int(row['pattern_2'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "\n",
    "N = len(query_patterns)\n",
    "print(f\"Number of pattern instances (N): {N}\")\n",
    "print(f\"Query patterns (first 10): {query_patterns[:10]}...\")\n",
    "if N != 94:\n",
    "    print(f\"Warning: Expected N = 94, but got N = {N}. Check query_labels_new_2.csv.\")\n",
    "\n",
    "# Step 3: Extract features and predictions using the original 15-class model\n",
    "retrieval_features = extract_features(retrieval_loader, model, device)  # (M, 512)\n",
    "query_features = extract_features(query_loader, model, device)  # (N, 512)\n",
    "\n",
    "# # Precompute predictions for the original 15 classes\n",
    "# predictions = np.zeros((M, num_classes))\n",
    "# with torch.no_grad():\n",
    "#     for images, _, folder_names in retrieval_loader:\n",
    "#         images = images.to(device)\n",
    "#         outputs = model(images)  # (batch_size, num_classes)\n",
    "#         batch_outputs = outputs.cpu().numpy()\n",
    "#         for i, folder_name in enumerate(folder_names):\n",
    "#             col_idx = object_indices[folder_name]\n",
    "#             predictions[col_idx] = batch_outputs[i]\n",
    "\n",
    "# # Step 4: Save predictions to text file (300 lines, 15 columns)\n",
    "# with open(\"predictionsVGG.txt\", \"w\") as f:\n",
    "#     for i in range(M):\n",
    "#         pred_line = \" \".join([f\"{x:.3f}\" for x in predictions[i]])\n",
    "#         f.write(pred_line + \"\\n\")\n",
    "# print(\"Predictions saved to predictionsVGG.txt\")\n",
    "\n",
    "# Step 5: Precompute predictions for the fine-tuned 4-class model\n",
    "# Assume model_4class is the fine-tuned model loaded elsewhere\n",
    "predictions_4class = np.zeros((M, num_classes_finetune))\n",
    "with torch.no_grad():\n",
    "    for images, _, folder_names in retrieval_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_4class(images)  # (batch_size, 4)\n",
    "        batch_outputs = outputs.cpu().numpy()\n",
    "        for i, folder_name in enumerate(folder_names):\n",
    "            col_idx = object_indices[folder_name]\n",
    "            predictions_4class[col_idx] = batch_outputs[i]\n",
    "\n",
    "# Save 4-class predictions to text file (300 lines, 4 columns)\n",
    "with open(\"predictions_4class.txt\", \"w\") as f:\n",
    "    for i in range(M):\n",
    "        pred_line = \" \".join([f\"{x:.3f}\" for x in predictions_4class[i]])\n",
    "        f.write(pred_line + \"\\n\")\n",
    "print(\"4-class predictions saved to predictions_4class.txt\")\n",
    "\n",
    "# # Step 6: Save retrieval features to text file (300 lines, 512 columns)\n",
    "# with open(\"retrieval_features.txt\", \"w\") as f:\n",
    "#     for i in range(M):\n",
    "#         feat_line = \" \".join([f\"{x:.6f}\" for x in retrieval_features[i]])\n",
    "#         f.write(feat_line + \"\\n\")\n",
    "# print(\"Retrieval features saved to retrieval_features.txt\")\n",
    "\n",
    "# # Step 7: Save query features to text file (94 lines, 512 columns)\n",
    "# query_folder_to_idx = {os.path.basename(folder_path): i for i, (folder_path, _) in enumerate(query_loader.dataset.samples)}\n",
    "# with open(\"query_featuresVGG.txt\", \"w\") as f:\n",
    "#     for file_index, pattern in query_patterns:\n",
    "#         patterns_for_file = [p for fi, p in query_patterns if fi == file_index]\n",
    "#         query_folder = (f\"{file_index}_pattern_{pattern}\" if len(patterns_for_file) == 1 \n",
    "#                         else f\"{file_index}_pattern_{'_'.join(map(str, patterns_for_file))}\")\n",
    "#         if query_folder not in query_folder_to_idx:\n",
    "#             print(f\"Warning: Query folder {query_folder} not found. Skipping...\")\n",
    "#             continue\n",
    "#         query_idx = query_folder_to_idx[query_folder]\n",
    "#         feat_line = \" \".join([f\"{x:.6f}\" for x in query_features[query_idx]])\n",
    "#         f.write(feat_line + \"\\n\")\n",
    "# print(\"Query features saved to query_featuresVGG.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec 2\n",
    "generating the matrix using feature similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths\n",
    "query_csv_path = \"query_labels_new_2.csv\"\n",
    "obj_dir = \"E:/Ahmed/IMT Nord Europe/3D/Retrieval_Screenshots_2\"\n",
    "num_classes = 15\n",
    "\n",
    "# Step 1: Get number of validation objects (M) and sort them ascendingly\n",
    "objects = [f for f in os.listdir(obj_dir) if os.path.isdir(os.path.join(obj_dir, f))]\n",
    "objects = sorted(objects, key=lambda x: int(x))\n",
    "M = len(objects)\n",
    "object_indices = {obj: i for i, obj in enumerate(objects)}\n",
    "print(f\"Number of objects (M): {M}\")\n",
    "\n",
    "# Step 2: Read query CSV and preserve exact pattern sequence\n",
    "query_df = pd.read_csv(query_csv_path)\n",
    "query_patterns = []\n",
    "pattern_labels = []\n",
    "\n",
    "for _, row in query_df.iterrows():\n",
    "    file_index = str(int(row['file_index']))\n",
    "    if pd.notna(row['pattern_1']):\n",
    "        pattern = int(row['pattern_1'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "        pattern_labels.append(f\"{file_index}_{pattern}\")\n",
    "    if pd.notna(row['pattern_2']):\n",
    "        pattern = int(row['pattern_2'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "        pattern_labels.append(f\"{file_index}_{pattern}\")\n",
    "\n",
    "N = len(query_patterns)\n",
    "print(f\"Number of pattern instances (N): {N}\")\n",
    "if N != 94:\n",
    "    print(f\"Warning: Expected N = 94, but got N = {N}.\")\n",
    "\n",
    "# Step 3: Load precomputed data from files\n",
    "# Load predictions (M x num_classes)\n",
    "predictions = np.loadtxt(\"predictionsVGG.txt\", dtype=float)  # (300, 15)\n",
    "assert predictions.shape == (M, num_classes), f\"Expected predictions shape ({M}, {num_classes}), got {predictions.shape}\"\n",
    "\n",
    "# Load retrieval features (M x 512)\n",
    "retrieval_features = np.loadtxt(\"retrieval_features.txt\", dtype=float)  # (300, 512)\n",
    "assert retrieval_features.shape[1] == 512, f\"Expected 512 features, got {retrieval_features.shape[1]}\"\n",
    "\n",
    "# Load query features (N x 512)\n",
    "query_features = np.loadtxt(\"query_featuresVGG.txt\", dtype=float)  # (94, 512)\n",
    "assert query_features.shape == (N, 512), f\"Expected query features shape ({N}, 512), got {query_features.shape}\"\n",
    "\n",
    "# Reorder query_features to match the order of query_patterns\n",
    "# Create the same mapping as in the first script\n",
    "query_folder_to_idx = {os.path.basename(folder_path): i for i, (folder_path, _) in enumerate(query_loader.dataset.samples)}\n",
    "reordered_query_features = np.zeros_like(query_features)  # (N, 512)\n",
    "\n",
    "for row_idx, (file_index, pattern) in enumerate(query_patterns):\n",
    "    patterns_for_file = [p for fi, p in query_patterns if fi == file_index]\n",
    "    query_folder = (f\"{file_index}_pattern_{pattern}\" if len(patterns_for_file) == 1 \n",
    "                    else f\"{file_index}_pattern_{'_'.join(map(str, patterns_for_file))}\")\n",
    "    if query_folder not in query_folder_to_idx:\n",
    "        print(f\"Warning: Query folder {query_folder} not found in query_loader. Using zeros for this row.\")\n",
    "        continue\n",
    "    query_idx = query_folder_to_idx[query_folder]\n",
    "    reordered_query_features[row_idx] = query_features[query_idx]\n",
    "\n",
    "# Precompute the maximum Euclidean distance for normalization\n",
    "all_distances = euclidean_distances(reordered_query_features, retrieval_features)  # (N, M)\n",
    "max_distance = np.max(all_distances)  # Maximum Euclidean distance for normalization\n",
    "if max_distance == 0:\n",
    "    print(\"Warning: Maximum Euclidean distance is 0. Setting similarities to 0.\")\n",
    "    max_distance = 1e-10  # Avoid division by zero\n",
    "\n",
    "# Step 4: Initialize membership matrix\n",
    "membership_matrix = np.zeros((N, M))\n",
    "\n",
    "# Step 5: Process each query pattern in sequence\n",
    "for row_idx, (file_index, pattern) in enumerate(query_patterns):\n",
    "    print(f\"Processing pattern {pattern} (row {row_idx}) for file_index {file_index}...\")\n",
    "\n",
    "    if pattern <= num_classes:\n",
    "        # Use precomputed predictions directly (no thresholding)\n",
    "        for col_idx in range(M):\n",
    "            membership_matrix[row_idx, col_idx] = predictions[col_idx, pattern - 1]\n",
    "    else:\n",
    "        # Feature-based similarity using normalized Euclidean distance\n",
    "        query_feature = reordered_query_features[row_idx:row_idx+1]  # (1, 512)\n",
    "        distances = euclidean_distances(query_feature, retrieval_features)[0]  # (M,)\n",
    "        # Normalize distances and compute similarities\n",
    "        similarities = 1 - (distances / max_distance)\n",
    "        similarities = np.clip(similarities, 0, 1)  # Ensure similarities are in [0, 1]\n",
    "        membership_matrix[row_idx] = similarities\n",
    "\n",
    "# Step 6: Save and generate files\n",
    "np.save(\"membership_matrix.npy\", membership_matrix)\n",
    "print(\"Membership matrix saved to membership_matrix.npy\")\n",
    "print(f\"Matrix shape: {membership_matrix.shape}\")\n",
    "\n",
    "# Generate membership_matrix.txt\n",
    "output_file = \"membership_matrix_VGG_Features.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"Membership Matrix (Pattern vs. Object Confidence Scores):\\n\")\n",
    "    header = \"Query   | \" + \" | \".join([f\"{obj[:5]:<5}\" for obj in objects])\n",
    "    f.write(header + \"\\n\")\n",
    "    f.write(\"-\" * len(header) + \"\\n\")\n",
    "    for i, (file_index, pattern) in enumerate(query_patterns):\n",
    "        row_values = membership_matrix[i]\n",
    "        row_str = f\"{file_index}_{pattern:<5} | \" + \" | \".join([f\"{score:.3f}\" for score in row_values])\n",
    "        f.write(row_str + \"\\n\")\n",
    "print(f\"Membership matrix saved to {output_file}\")\n",
    "\n",
    "# Generate competition submission file (NameParticipant_run1.txt)\n",
    "submission_file = \"NameParticipant_run1_VGG_Features.txt\"\n",
    "with open(submission_file, 'w') as f:\n",
    "    for i in range(N):\n",
    "        row_values = membership_matrix[i]\n",
    "        f.write(\" \".join([f\"{score:.3f}\" for score in row_values]) + \"\\n\")\n",
    "print(f\"Competition submission file saved to {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec 3\n",
    "generating the matrix using the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is for the second approach of producing the matrice from the two classes.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths\n",
    "query_csv_path = \"query_labels_new_2.csv\"\n",
    "obj_dir = \"D:/3D/Retrieval_Screenshots_2\"\n",
    "num_classes = 15  # Original classes\n",
    "num_classes_finetune = 4  # Fine-tuned classes (patterns 16-19, re-indexed as 0-3)\n",
    "\n",
    "# Step 1: Get number of validation objects (M) and sort them ascendingly\n",
    "objects = [f for f in os.listdir(obj_dir) if os.path.isdir(os.path.join(obj_dir, f))]\n",
    "objects = sorted(objects, key=lambda x: int(x))\n",
    "M = len(objects)\n",
    "object_indices = {obj: i for i, obj in enumerate(objects)}\n",
    "print(f\"Number of objects (M): {M}\")\n",
    "\n",
    "# Step 2: Read query CSV and preserve exact pattern sequence\n",
    "query_df = pd.read_csv(query_csv_path)\n",
    "query_patterns = []\n",
    "pattern_labels = []\n",
    "\n",
    "for _, row in query_df.iterrows():\n",
    "    file_index = str(int(row['file_index']))\n",
    "    if pd.notna(row['pattern_1']):\n",
    "        pattern = int(row['pattern_1'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "        pattern_labels.append(f\"{file_index}_{pattern}\")\n",
    "    if pd.notna(row['pattern_2']):\n",
    "        pattern = int(row['pattern_2'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "        pattern_labels.append(f\"{file_index}_{pattern}\")\n",
    "\n",
    "N = len(query_patterns)\n",
    "print(f\"Number of pattern instances (N): {N}\")\n",
    "if N != 94:\n",
    "    print(f\"Warning: Expected N = 94, but got N = {N}.\")\n",
    "\n",
    "# Step 3: Load precomputed data from files\n",
    "# Load predictions for original 15 classes (M x num_classes)\n",
    "predictions = np.loadtxt(\"predictions.txt\", dtype=float)  # (300, 15)\n",
    "assert predictions.shape == (M, num_classes), f\"Expected predictions shape ({M}, {num_classes}), got {predictions.shape}\"\n",
    "\n",
    "# Load predictions for fine-tuned 4 classes (M x 4)\n",
    "predictions_4class = np.loadtxt(\"predictions_4class.txt\", dtype=float)  # (300, 4)\n",
    "assert predictions_4class.shape == (M, num_classes_finetune), f\"Expected 4-class predictions shape ({M}, {num_classes_finetune}), got {predictions_4class.shape}\"\n",
    "\n",
    "# Load retrieval features (M x 512)\n",
    "retrieval_features = np.loadtxt(\"retrieval_features.txt\", dtype=float)  # (300, 512)\n",
    "assert retrieval_features.shape[1] == 512, f\"Expected 512 features, got {retrieval_features.shape[1]}\"\n",
    "\n",
    "# Load query features (N x 512)\n",
    "query_features = np.loadtxt(\"query_features.txt\", dtype=float)  # (94, 512)\n",
    "assert query_features.shape == (N, 512), f\"Expected query features shape ({N}, 512), got {query_features.shape}\"\n",
    "\n",
    "# Step 4: Initialize membership matrix\n",
    "membership_matrix = np.zeros((N, M))\n",
    "\n",
    "# Step 5: Process each query pattern in sequence\n",
    "for row_idx, (file_index, pattern) in enumerate(query_patterns):\n",
    "    print(f\"Processing pattern {pattern} (row {row_idx}) for file_index {file_index}...\")\n",
    "\n",
    "    if pattern <= num_classes:  # Patterns 1-15 (0-14 in zero-based indexing)\n",
    "        # Use precomputed predictions from the original 15-class model\n",
    "        for col_idx in range(M):\n",
    "            membership_matrix[row_idx, col_idx] = predictions[col_idx, pattern - 1]\n",
    "    else:  # Patterns 16-19 (fine-tuned classes 0-3)\n",
    "        # Use predictions from the fine-tuned 4-class model\n",
    "        class_idx = pattern - 16  # Map pattern 160, 171, 182, 193\n",
    "        for col_idx in range(M):\n",
    "            membership_matrix[row_idx, col_idx] = predictions_4class[col_idx, class_idx]\n",
    "\n",
    "# Step 6: Save and generate files\n",
    "np.save(\"membership_matrix.npy\", membership_matrix)\n",
    "print(\"Membership matrix saved to membership_matrix.npy\")\n",
    "print(f\"Matrix shape: {membership_matrix.shape}\")\n",
    "\n",
    "# Generate membership_matrix.txt with compact header\n",
    "output_file = \"membership_matrix.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"Membership Matrix (Pattern vs. Object Confidence Scores):\\n\")\n",
    "    header = \"Query   | \" + \" | \".join([f\"{obj[:5]:<5}\" for obj in objects])\n",
    "    f.write(header + \"\\n\")\n",
    "    f.write(\"-\" * len(header) + \"\\n\")\n",
    "    for i, (file_index, pattern) in enumerate(query_patterns):\n",
    "        row_values = membership_matrix[i]\n",
    "        row_str = f\"{file_index}_{pattern:<5} | \" + \" | \".join([f\"{score:.3f}\" for score in row_values])\n",
    "        f.write(row_str + \"\\n\")\n",
    "print(f\"Membership matrix saved to {output_file}\")\n",
    "\n",
    "# Generate competition submission file (NameParticipant_run1.txt)\n",
    "submission_file = \"NameParticipant_run1.txt\"\n",
    "with open(submission_file, 'w') as f:\n",
    "    for i in range(N):\n",
    "        row_values = membership_matrix[i]\n",
    "        f.write(\" \".join([f\"{score:.3f}\" for score in row_values]) + \"\\n\")\n",
    "print(f\"Competition submission file saved to {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation in membership matrix (not used anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths\n",
    "query_csv_path = \"query_labels_new_2.csv\"\n",
    "obj_dir = \"D:/3D/Retrieval_Screenshots\"\n",
    "num_classes = 15  # From your setup\n",
    "\n",
    "# Step 1: Get number of validation objects (M) and sort them ascendingly\n",
    "objects = [f for f in os.listdir(obj_dir) if os.path.isdir(os.path.join(obj_dir, f))]\n",
    "# Sort objects by integer value of their names\n",
    "objects = sorted(objects, key=lambda x: int(x))\n",
    "M = len(objects)\n",
    "object_indices = {obj: i for i, obj in enumerate(objects)}\n",
    "print(f\"Number of objects (M): {M}\")\n",
    "print(f\"Sorted objects: {objects[:10]}...\")  # Debug: Show first 10 objects\n",
    "\n",
    "# Step 2: Read query CSV and preserve exact pattern sequence\n",
    "query_df = pd.read_csv(query_csv_path)\n",
    "query_patterns = []  # List of (file_index, pattern) tuples in order of appearance\n",
    "pattern_labels = []  # For labeling rows in visualization\n",
    "\n",
    "for _, row in query_df.iterrows():\n",
    "    file_index = str(int(row['file_index']))\n",
    "    if pd.notna(row['pattern_1']):\n",
    "        pattern = int(row['pattern_1'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "        pattern_labels.append(f\"{file_index}_{pattern}\")\n",
    "    if pd.notna(row['pattern_2']):\n",
    "        pattern = int(row['pattern_2'])\n",
    "        query_patterns.append((file_index, pattern))\n",
    "        pattern_labels.append(f\"{file_index}_{pattern}\")\n",
    "\n",
    "N = len(query_patterns)\n",
    "print(f\"Number of pattern instances (N): {N}\")\n",
    "print(f\"Query patterns (first 10): {query_patterns[:10]}...\")  # Debug: Show first 10\n",
    "\n",
    "# Verify N matches expected value\n",
    "if N != 94:\n",
    "    print(f\"Warning: Expected N = 94, but got N = {N}. Check query_labels_new_2.csv for consistency.\")\n",
    "\n",
    "# Step 3: Initialize membership matrix\n",
    "membership_matrix = np.zeros((N, M))\n",
    "\n",
    "# Step 4: Extract features and predictions once\n",
    "retrieval_features = extract_features(retrieval_loader, model, device)  # (M, 512)\n",
    "query_features = extract_features(query_loader, model, device)  # (num_queries, 512)\n",
    "\n",
    "# Precompute predictions for trained classes\n",
    "predictions = np.zeros((M, num_classes))\n",
    "with torch.no_grad():\n",
    "    offset = 0\n",
    "    for images, _, folder_names in retrieval_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)  # (batch_size, num_classes)\n",
    "        batch_size = outputs.size(0)\n",
    "        batch_outputs = outputs.cpu().numpy()\n",
    "        batch_preds = (batch_outputs > 0.5).astype(float)\n",
    "        for i, folder_name in enumerate(folder_names):\n",
    "            col_idx = object_indices[folder_name]\n",
    "            predictions[col_idx] = batch_outputs[i]\n",
    "            if batch_preds[i].any():\n",
    "                membership_matrix[:, col_idx] = 0  # Reset for later update\n",
    "        offset += batch_size\n",
    "\n",
    "# Step 5: Process each query pattern in sequence\n",
    "query_folder_to_idx = {os.path.basename(folder_path): i for i, (folder_path, _) in enumerate(query_loader.dataset.samples)}\n",
    "\n",
    "for row_idx, (file_index, pattern) in enumerate(query_patterns):\n",
    "    print(f\"Processing pattern {pattern} (row {row_idx}) for file_index {file_index}...\")\n",
    "\n",
    "    if pattern <= num_classes:\n",
    "        # Use precomputed predictions\n",
    "        for col_idx in range(M):\n",
    "            membership_matrix[row_idx, col_idx] = predictions[col_idx, pattern - 1]\n",
    "\n",
    "    else:\n",
    "        # Feature-based similarity\n",
    "        # Construct folder name based on all patterns for this file_index\n",
    "        patterns_for_file = [p for fi, p in query_patterns if fi == file_index]\n",
    "        query_folder = (f\"{file_index}_pattern_{pattern}\" if len(patterns_for_file) == 1 \n",
    "                        else f\"{file_index}_pattern_{'_'.join(map(str, patterns_for_file))}\")\n",
    "        if query_folder not in query_folder_to_idx:\n",
    "            print(f\"Warning: Query folder {query_folder} not found in query_loader. Skipping...\")\n",
    "            continue\n",
    "        query_idx = query_folder_to_idx[query_folder]\n",
    "        query_feature = query_features[query_idx:query_idx+1]  # (1, 512)\n",
    "        similarities = 1 - (distances / max_distance)\n",
    "        similarities = np.clip(similarities, 0, 1)  # Ensure similarities are in [0, 1]\n",
    "        membership_matrix[row_idx] = similarities\n",
    "\n",
    "# Step 6: Save and generate files\n",
    "np.save(\"membership_matrix.npy\", membership_matrix)\n",
    "print(\"Membership matrix saved to membership_matrix.npy\")\n",
    "print(f\"Matrix shape: {membership_matrix.shape}\")\n",
    "\n",
    "# Generate membership_matrix.txt with compact header\n",
    "output_file = \"membership_matrix.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"Membership Matrix (Pattern vs. Object Confidence Scores):\\n\")\n",
    "    header = \"Query   | \" + \" | \".join([f\"{obj[:5]:<5}\" for obj in objects])  # Compact header\n",
    "    f.write(header + \"\\n\")\n",
    "    f.write(\"-\" * len(header) + \"\\n\")\n",
    "    for i, (file_index, pattern) in enumerate(query_patterns):\n",
    "        row_values = membership_matrix[i]\n",
    "        row_str = f\"{file_index}_{pattern:<5} | \" + \" | \".join([f\"{score:.3f}\" for score in row_values])\n",
    "        f.write(row_str + \"\\n\")\n",
    "print(f\"Membership matrix saved to {output_file}\")\n",
    "\n",
    "# Generate competition submission file (NameParticipant_run1.txt)\n",
    "submission_file = \"NameParticipant_run1.txt\"\n",
    "with open(submission_file, 'w') as f:\n",
    "    for i in range(N):\n",
    "        row_values = membership_matrix[i]\n",
    "        f.write(\" \".join([f\"{score:.3f}\" for score in row_values]) + \"\\n\")\n",
    "print(f\"Competition submission file saved to {submission_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
